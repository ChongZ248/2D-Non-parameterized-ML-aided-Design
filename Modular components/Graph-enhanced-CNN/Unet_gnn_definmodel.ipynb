{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "# from Meshpoolscr import MeshPooling\n",
    "# def cnntogra(pos,batch,datatomap):\n",
    "#     imageindex=batch\n",
    "#     posindexT=torch.round(pos/20*(datatomap.shape[-1]-1)).long()\n",
    "#     posindex=torch.stack((posindexT[:,1],posindexT[:,0]),dim=-1)\n",
    "#     # Select the right \"image\" using imageindex\n",
    "#     selected_images = datatomap[imageindex]\n",
    "#     # Now use posindex to index into the last two dimensions\n",
    "#     result = selected_images[torch.arange(selected_images.shape[0]), :, posindex[:, 0], posindex[:, 1]]\n",
    "#     return result\n",
    "\n",
    "def cnntogra(pos, batch, datatomap):\n",
    "    # this is a function to convert the batch of CNN data to the corresponding graph data based on the node position\n",
    "    # the graph data is a batched graph therefore the \"batch\" is needed to distinguish the different sub graphs\n",
    "    # datatomap is the CNN data with the shape of [batch_size, 1, height, width]\n",
    "    # pos have the shape of [node_number, 2]\n",
    "    # batch have the shape of [node_number]\n",
    "    unique_indices, inverse_indices = torch.unique(batch, return_inverse=True)\n",
    "    posindexT = torch.round(pos / 20 * (datatomap.shape[-1] - 1)).long()\n",
    "    posindex = torch.stack((posindexT[:, 1], posindexT[:, 0]), dim=-1)\n",
    "    selected_images = datatomap[unique_indices]\n",
    "    result = selected_images[inverse_indices, :, posindex[:, 0], posindex[:, 1]]\n",
    "    return result\n",
    "\n",
    "\n",
    "def gratocnn(resultfromgnn,pos,batch,oldcnn):\n",
    "    imageindex=batch\n",
    "    # Example tensors for demonstration\n",
    "    batchedimage =  torch.ones(oldcnn.shape[0], resultfromgnn.shape[-1], oldcnn.shape[2], oldcnn.shape[3]).to(oldcnn.device)*-10 # This can be of different sizes now\n",
    "    pixelvalue = resultfromgnn  # Random values\n",
    "    imageindex = imageindex.unsqueeze(dim=-1)  # Adjusted to batch size\n",
    "    posindexT=torch.round(pos/20*(oldcnn.shape[-1]-1)).long()\n",
    "    posindex=torch.stack((posindexT[:,1],posindexT[:,0]),dim=-1)\n",
    "    # Flatten the batchedimage tensor\n",
    "    batchedimage_flat = batchedimage.view(batchedimage.size(0), batchedimage.size(1), -1)\n",
    "    # Get image dimensions\n",
    "    img_height, img_width = batchedimage.size(2), batchedimage.size(3)\n",
    "    # Calculate the linear indices\n",
    "    linear_indices = posindex[:, 0] * img_width + posindex[:, 1]\n",
    "    # Use advanced indexin to assign values\n",
    "    batchedimage_flat[imageindex[:, 0], :, linear_indices] = pixelvalue\n",
    "    # Reshape back to original shape\n",
    "    batchedimage = batchedimage_flat.view(batchedimage.size(0), batchedimage.size(1), img_height, img_width)\n",
    "    return batchedimage\n",
    "\n",
    "def cnntogra_pad(pos_nopad,batch,datatomap):\n",
    "    pos=pos_nopad+torch.tensor([20/8,20/8])\n",
    "    imageindex=batch\n",
    "    posindexT=torch.round(pos/(20*5/4)*(datatomap.shape[-1]-1)).long()\n",
    "    posindex=torch.stack((posindexT[:,1],posindexT[:,0]),dim=-1)\n",
    "    # Select the right \"image\" using imageindex\n",
    "    selected_images = datatomap[imageindex]\n",
    "    # Now use posindex to index into the last two dimensions\n",
    "    result = selected_images[torch.arange(selected_images.shape[0]), :, posindex[:, 0], posindex[:, 1]]\n",
    "    return result\n",
    "def gratocnn_pad(resultfromgnn,pos_nopad,batch,oldcnn):\n",
    "    pos=pos_nopad+torch.tensor([20/8,20/8])\n",
    "    imageindex=batch\n",
    "    # Example tensors for demonstration\n",
    "    batchedimage =  torch.ones(oldcnn.shape[0], resultfromgnn.shape[-1], oldcnn.shape[2], oldcnn.shape[3])*-10 # This can be of different sizes now\n",
    "    pixelvalue = resultfromgnn  # Random values\n",
    "    imageindex = imageindex.unsqueeze(dim=-1)  # Adjusted to batch size\n",
    "    posindexT=torch.round(pos/(20*5/4)*(oldcnn.shape[-1]-1)).long()\n",
    "    posindex=torch.stack((posindexT[:,1],posindexT[:,0]),dim=-1)\n",
    "    # Flatten the batchedimage tensor\n",
    "    batchedimage_flat = batchedimage.view(batchedimage.size(0), batchedimage.size(1), -1)\n",
    "    # Get image dimensions\n",
    "    img_height, img_width = batchedimage.size(2), batchedimage.size(3)\n",
    "    # Calculate the linear indices\n",
    "    linear_indices = posindex[:, 0] * img_width + posindex[:, 1]\n",
    "    # Use advanced indexin to assign values\n",
    "    batchedimage_flat[imageindex[:, 0], :, linear_indices] = pixelvalue\n",
    "    # Reshape back to original shape\n",
    "    batchedimage = batchedimage_flat.view(batchedimage.size(0), batchedimage.size(1), img_height, img_width)\n",
    "    return batchedimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plotedges(pos,edge_index,figindex):\n",
    "    fig=plt.figure()\n",
    "    posss=np.array(pos.cpu().detach())\n",
    "    print(pos.shape)\n",
    "    print(edge_index.shape)\n",
    "    d = dict(enumerate(posss, 0))\n",
    "    edgess=np.array(edge_index.cpu().detach()).T\n",
    "    for i in edgess:\n",
    "        plt.plot([d[i[0]][0],d[i[1]][0]],[d[i[0]][1],d[i[1]][1]],linewidth=0.1,c='b',alpha=0.5)\n",
    "        # print(d[i[0]],d[i[1]])\n",
    "    plt.axis('equal')\n",
    "    plt.savefig(str(figindex)+'boundpoo.svg')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_scatter import scatter_add\n",
    "\n",
    "class DenseGraphSAGELayerV3(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, aggregation='sum', bias=True):\n",
    "        super(DenseGraphSAGELayerV3, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.aggregation = aggregation  # 'sum' 或 'mean'\n",
    "\n",
    "        self.weight_self = torch.nn.Linear(in_channels, out_channels, bias=False)\n",
    "        self.weight_neighbor = torch.nn.Linear(in_channels, out_channels, bias=False)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = torch.nn.Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.weight_self.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.weight_neighbor.weight)\n",
    "        if self.bias is not None:\n",
    "            torch.nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        x: (N, in_channels)  # 节点特征矩阵\n",
    "        edge_index: (2, E)  # 边索引，表示图的连接关系\n",
    "        \"\"\"\n",
    "        src, dst = edge_index  # 提取边的起点和终点\n",
    "\n",
    "        out_self = self.weight_self(x)  # 计算每个节点的自特征变换 (N, out_channels)\n",
    "\n",
    "        # 计算邻居的特征差值\n",
    "        diff = x[src] - x[dst]  # (E, in_channels)\n",
    "\n",
    "        # 对差值应用变换\n",
    "        diff_transformed = self.weight_neighbor(diff)  # (E, out_channels)\n",
    "\n",
    "        # 聚合邻居消息\n",
    "        out_neighbors = scatter_add(diff_transformed, dst, dim=0, dim_size=x.size(0))  # (N, out_channels)\n",
    "\n",
    "        if self.aggregation == 'mean':\n",
    "            deg = scatter_add(torch.ones_like(dst, dtype=torch.float), dst, dim=0, dim_size=x.size(0)).unsqueeze(-1)\n",
    "            deg[deg == 0] = 1  # 避免除零\n",
    "            out_neighbors /= deg\n",
    "\n",
    "        out = out_self + out_neighbors  # (N, out_channels)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class GraphSAGEV3(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_layers, out_channels, dropout=0.0, aggregation='sum'):\n",
    "        super(GraphSAGEV3, self).__init__()\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        # Input layer\n",
    "        self.layers.append(DenseGraphSAGELayerV3(in_channels, hidden_channels, aggregation))\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.layers.append(DenseGraphSAGELayerV3(hidden_channels, hidden_channels, aggregation))\n",
    "\n",
    "        # Output layer\n",
    "        self.layers.append(DenseGraphSAGELayerV3(hidden_channels, out_channels, aggregation))\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.layers[i](x, adj)\n",
    "            if i < self.num_layers - 1:\n",
    "                x = self.dropout(torch.nn.functional.relu(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}(in_channels={}, hidden_channels={}, num_layers={}, out_channels={}, dropout={})'.format(\n",
    "            self.__class__.__name__, self.layers[0].in_channels, self.layers[1].in_channels, self.num_layers, self.layers[-1].out_channels, self.dropout.p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Stressnet import Modfiedunet4shrink,Modfiedunet_CMAME,Modfiedunet3shrink_CMAME, Modfiedunet3shrink,StressNetori,StressNetgit,StressNetgit4shrink,Modfiedunet\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CNNadgnn(nn.Module): ###https://doi.org/10.1016/j.mechmat.2021.104191\n",
    "    def __init__(self,chlist=[8,32,64,128,128,128,128,128,64,32,9]):\n",
    "        super().__init__()\n",
    "        self.c1=Modfiedunet4shrink()\n",
    "        self.g1=GraphSAGE(in_channels=int(8),hidden_channels=int(128), \n",
    "                                num_layers=4, out_channels=1)\n",
    "    def forward(self, igra):\n",
    "        x=igra.xdata128.float()\n",
    "        gx,edge_index,posnew,pollinfor,batchinfo=igra.x,igra.edge_index,igra.pos.float(),igra.pollinfor,igra.batch\n",
    "        gx=torch.cat((igra.x[:,0:2],igra.x[:,-3:],posnew),dim=-1).float()\n",
    "        x1=self.c1(x)\n",
    "        cnng=cnntogra(posnew,batchinfo,x1)\n",
    "        # print(gx.shape,cnng.shape)\n",
    "        gout=self.g1(torch.cat((gx,cnng),dim=-1),edge_index)\n",
    "        return x1,gout\n",
    "    \n",
    "class CNNadgnn_cnn1ch(nn.Module): ###https://doi.org/10.1016/j.mechmat.2021.104191\n",
    "    def __init__(self,chlist=[8,32,64,128,128,128,128,128,64,32,9]):\n",
    "        super().__init__()\n",
    "        self.c1=Modfiedunet4shrink()\n",
    "        self.g1=GraphSAGE(in_channels=int(8),hidden_channels=int(128), \n",
    "                                num_layers=4, out_channels=1)\n",
    "    def forward(self, igra):\n",
    "        x=igra.xdata128.float()\n",
    "        first_channel = x[:, 0:1, :, :]\n",
    "        x= first_channel.repeat(1, 6, 1, 1)\n",
    "        gx,edge_index,posnew,pollinfor,batchinfo=igra.x,igra.edge_index,igra.pos.float(),igra.pollinfor,igra.batch\n",
    "        gx=torch.cat((igra.x[:,0:2],igra.x[:,-3:],posnew),dim=-1).float()\n",
    "        print(x.shape)\n",
    "        x1=self.c1(x)\n",
    "        print(x1.shape)\n",
    "        # print the number of parameters in c1\n",
    "        print(sum(p.numel() for p in self.c1.parameters()))\n",
    "        cnng=cnntogra(posnew,batchinfo,x1)\n",
    "        # print(gx.shape,cnng.shape)\n",
    "        gout=self.g1(torch.cat((gx,cnng),dim=-1),edge_index)\n",
    "        return x1,gout\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models.segmentation as segmentation\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "class CNNadgnn_cnn1ch(nn.Module):\n",
    "    def __init__(self, chlist=[8, 32, 64, 128, 128, 128, 128, 128, 64, 32, 9]):\n",
    "        super().__init__()\n",
    "        self.segmentation_model = segmentation.lraspp_mobilenet_v3_large(num_classes=1)\n",
    "        self.segmentation_model.train()  # Make sure to set to training mode if required\n",
    "        self.g1 = GraphSAGE(in_channels=int(8), hidden_channels=int(128), num_layers=4, out_channels=1)\n",
    "\n",
    "    def forward(self, igra):\n",
    "        x = igra.xdata128.float()\n",
    "        original_size = x.shape[-2:]  # Save the original size for resizing later\n",
    "\n",
    "        # Process the first channel and resize to 224x224\n",
    "        first_channel = x[:, 0:1, :, :]\n",
    "        resized_input = TF.resize(first_channel.repeat(1, 3, 1, 1), size=(224, 224))\n",
    "\n",
    "        # Feed into the segmentation model\n",
    "        segmentation_output = self.segmentation_model(resized_input)['out']\n",
    "        \n",
    "        ### Resize output back to original size\n",
    "        resized_output = TF.resize(segmentation_output, size=original_size)\n",
    "        ### print the range of the output\n",
    "        # print(resized_output.min(), resized_output.max())\n",
    "        # print(resized_output.shape)\n",
    "        # print(sum(p.numel() for p in self.segmentation_model.parameters()))\n",
    "\n",
    "        gx, edge_index, posnew, pollinfor, batchinfo = igra.x, igra.edge_index, igra.pos.float(), igra.pollinfor, igra.batch\n",
    "        gx = torch.cat((igra.x[:, 0:2], igra.x[:, -3:], posnew), dim=-1).float()\n",
    "\n",
    "        cnng = cnntogra(posnew, batchinfo, resized_output)  # Assuming cnntogra can handle the resized output\n",
    "\n",
    "        # Combine CNN features with graph features\n",
    "        gout = self.g1(torch.cat((gx, cnng), dim=-1), edge_index)\n",
    "\n",
    "        return resized_output, gout\n",
    "\n",
    "\n",
    "\n",
    "class CNNadgnn_cnn1ch_cnnonly(nn.Module):\n",
    "    def __init__(self, chlist=[8, 32, 64, 128, 128, 128, 128, 128, 64, 32, 9]):\n",
    "        super().__init__()\n",
    "        self.segmentation_model = segmentation.lraspp_mobilenet_v3_large(num_classes=1)\n",
    "        self.segmentation_model.train()  # Make sure to set to training mode if required\n",
    "        self.linear = nn.Linear(8, 1)\n",
    "    def forward(self, igra):\n",
    "        x = igra.xdata128.float()\n",
    "        original_size = x.shape[-2:]  # Save the original size for resizing later\n",
    "\n",
    "        # Process the first channel and resize to 224x224\n",
    "        first_channel = x[:, 0:1, :, :]\n",
    "        resized_input = TF.resize(first_channel.repeat(1, 3, 1, 1), size=(224, 224))\n",
    "\n",
    "        # Feed into the segmentation model\n",
    "        segmentation_output = self.segmentation_model(resized_input)['out']\n",
    "        \n",
    "        ### Resize output back to original size\n",
    "        resized_output = TF.resize(segmentation_output, size=original_size)\n",
    "        ### print the range of the output\n",
    "        # print(resized_output.min(), resized_output.max())\n",
    "        # print(resized_output.shape)\n",
    "        # print(sum(p.numel() for p in self.segmentation_model.parameters()))\n",
    "\n",
    "        gx, edge_index, posnew, pollinfor, batchinfo = igra.x, igra.edge_index, igra.pos.float(), igra.pollinfor, igra.batch\n",
    "        gx = torch.cat((igra.x[:, 0:2], igra.x[:, -3:], posnew), dim=-1).float()\n",
    "\n",
    "        cnng = cnntogra(posnew, batchinfo, resized_output)  # Assuming cnntogra can handle the resized output\n",
    "\n",
    "        # Combine CNN features with graph features\n",
    "        # gout = self.g1(torch.cat((gx, cnng), dim=-1), edge_index)\n",
    "        gout = self.linear(torch.cat((gx, cnng), dim=-1))\n",
    "\n",
    "        return resized_output, gout\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device='cuda'\n",
    "class CNNadgnn_cnn1chv2(nn.Module): ###https://doi.org/10.1016/j.mechmat.2021.104191\n",
    "    def __init__(self,chlist=[8,32,64,128,128,128,128,128,64,32,9]):\n",
    "        super().__init__()\n",
    "        self.c1=Modfiedunet4shrink(chin=1)\n",
    "        self.g1=GraphSAGE(in_channels=int(8),hidden_channels=int(128), \n",
    "                                num_layers=4, out_channels=1)\n",
    "    def forward(self, igra):\n",
    "        x=igra.xdata128.float()\n",
    "        first_channel = x[:, 0:1, :, :]\n",
    "        x= first_channel\n",
    "        gx,edge_index,posnew,pollinfor,batchinfo=igra.x,igra.edge_index,igra.pos.float(),igra.pollinfor,igra.batch\n",
    "        gx=torch.cat((igra.x[:,0:2],igra.x[:,-3:],posnew),dim=-1).float()\n",
    "        x1=self.c1(x)\n",
    "        cnng=cnntogra(posnew,batchinfo,x1)\n",
    "        gout=self.g1(torch.cat((gx,cnng),dim=-1),edge_index)\n",
    "        return x1,gout\n",
    " \n",
    "class CNNadgnnIdent(nn.Module): ###https://doi.org/10.1016/j.mechmat.2021.104191\n",
    "    def __init__(self,chlist=[8,32,64,128,128,128,128,128,64,32,9]):\n",
    "        super().__init__()\n",
    "        self.c1=Modfiedunet4shrink(chin=1)\n",
    "        # self.g1=GraphSAGE(in_channels=int(8),hidden_channels=int(128), \n",
    "        #                         num_layers=4, out_channels=1)\n",
    "        #create a mlp (8,128,128,128,1)\n",
    "        self.mlp=nn.Sequential(\n",
    "            nn.Linear(8,128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128,128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128,128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128,128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128,1)\n",
    "        )\n",
    "    def forward(self, igra):\n",
    "        x=igra.xdata128.float()\n",
    "        first_channel = x[:, 0:1, :, :]\n",
    "        x= first_channel\n",
    "\n",
    "        gx,edge_index,posnew,pollinfor,batchinfo=igra.x,igra.edge_index,igra.pos.float(),igra.pollinfor,igra.batch\n",
    "        gx=torch.cat((igra.x[:,0:2],igra.x[:,-3:],posnew),dim=-1).float()\n",
    "        x1=self.c1(x)\n",
    "        cnng=cnntogra(posnew,batchinfo,x1)\n",
    "        # print(gx.shape,cnng.shape)\n",
    "        # gout=self.g1(torch.cat((gx,cnng),dim=-1),edge_index)\n",
    "        gout = self.mlp(torch.cat((gx, cnng), dim=-1))\n",
    "        return x1,gout\n",
    "\n",
    "class CNNadgnnIdent_GNN(nn.Module): ###https://doi.org/10.1016/j.mechmat.2021.104191\n",
    "    def __init__(self,chlist=[8,32,64,128,128,128,128,128,64,32,9]):\n",
    "        super().__init__()\n",
    "        self.c1=Modfiedunet4shrink(chin=1)\n",
    "        self.g1=GraphSAGE(in_channels=int(8),hidden_channels=int(128), \n",
    "                                num_layers=4, out_channels=1)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, igra):\n",
    "        x=igra.xdata128.float()\n",
    "        first_channel = x[:, 0:1, :, :]\n",
    "        x= first_channel\n",
    "\n",
    "        gx,edge_index,posnew,pollinfor,batchinfo=igra.x,igra.edge_index,igra.pos.float(),igra.pollinfor,igra.batch\n",
    "        gx=torch.cat((igra.x[:,0:2],igra.x[:,-3:],posnew),dim=-1).float()\n",
    "        x1=self.c1(x)\n",
    "        cnng=cnntogra(posnew,batchinfo,x1)\n",
    "        # print(gx.shape,cnng.shape)\n",
    "        gout=self.g1(torch.cat((gx,cnng),dim=-1),edge_index)\n",
    "        return x1,gout\n",
    "\n",
    "\n",
    "class CNNadgnnIdent_SA_GNN(nn.Module): ###https://doi.org/10.1016/j.mechmat.2021.104191\n",
    "    def __init__(self,chlist=[8,32,64,128,128,128,128,128,64,32,9]):\n",
    "        super().__init__()\n",
    "        self.c1=Modfiedunet4shrink(chin=1)\n",
    "        # self.g1=GraphSAGE(in_channels=int(8),hidden_channels=int(128), \n",
    "        #                         num_layers=4, out_channels=1)\n",
    "        \n",
    "        self.g1=GraphSAGEV3(in_channels=int(8),hidden_channels=int(128), \n",
    "                                num_layers=4, out_channels=1)\n",
    "\n",
    "    def forward(self, igra):\n",
    "        x=igra.xdata128.float()\n",
    "        first_channel = x[:, 0:1, :, :]\n",
    "        x= first_channel\n",
    "\n",
    "        gx,edge_index,posnew,pollinfor,batchinfo=igra.x,igra.edge_index,igra.pos.float(),igra.pollinfor,igra.batch\n",
    "        gx=torch.cat((igra.x[:,0:2],igra.x[:,-3:],posnew),dim=-1).float()\n",
    "        x1=self.c1(x)\n",
    "        cnng=cnntogra(posnew,batchinfo,x1)\n",
    "        # print(gx.shape,cnng.shape)\n",
    "        gout=self.g1(torch.cat((gx,cnng),dim=-1),edge_index)\n",
    "        return x1,gout\n",
    "\n",
    "\n",
    "class CNNadgnnIdent_small(nn.Module): ###https://doi.org/10.1016/j.mechmat.2021.104191\n",
    "    def __init__(self,chlist=[8,32,64,128,128,128,128,128,64,32,9]):\n",
    "        super().__init__()\n",
    "        self.c1=Modfiedunet4shrink(chin=1,k=4)\n",
    "        # self.c1=Modfiedunet_CMAME(chin=1)\n",
    "        # self.c1=Modfiedunet3shrink_CMAME(chin=1,k=8)\n",
    "        # self.g1=GraphSAGE(in_channels=int(8),hidden_channels=int(128), \n",
    "        #                         num_layers=4, out_channels=1)\n",
    "        #create a mlp (8,128,128,128,1)\n",
    "        hidden=32\n",
    "        self.mlp=nn.Sequential(\n",
    "            nn.Linear(8,hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden,hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden,hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden,hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden,1)\n",
    "        )\n",
    "    def forward(self, igra):\n",
    "        x=igra.xdata128.float()\n",
    "        first_channel = x[:, 0:1, :, :]\n",
    "        x= first_channel\n",
    "\n",
    "        gx,edge_index,posnew,pollinfor,batchinfo=igra.x,igra.edge_index,igra.pos.float(),igra.pollinfor,igra.batch\n",
    "        gx=torch.cat((igra.x[:,0:2],igra.x[:,-3:],posnew),dim=-1).float()\n",
    "        x1=self.c1(x)\n",
    "        cnng=cnntogra(posnew,batchinfo,x1)\n",
    "        # print(gx.shape,cnng.shape)\n",
    "        # gout=self.g1(torch.cat((gx,cnng),dim=-1),edge_index)\n",
    "        gout = self.mlp(torch.cat((gx, cnng), dim=-1))\n",
    "        return x1,gout\n",
    "\n",
    "class CNNadgnnIdent_GNN_small(nn.Module): ###https://doi.org/10.1016/j.mechmat.2021.104191\n",
    "    def __init__(self,chlist=[8,32,64,128,128,128,128,128,64,32,9]):\n",
    "        super().__init__()\n",
    "        self.c1=Modfiedunet4shrink(chin=1,k=4)\n",
    "        # self.c1=Modfiedunet_CMAME(chin=1)\n",
    "        # self.c1=Modfiedunet3shrink_CMAME(chin=1,k=8)\n",
    "        self.g1=GraphSAGE(in_channels=int(8),hidden_channels=int(32), \n",
    "                                num_layers=4, out_channels=1)\n",
    "    def forward(self, igra):\n",
    "        x=igra.xdata128.float()\n",
    "        first_channel = x[:, 0:1, :, :]\n",
    "        x= first_channel\n",
    "\n",
    "        gx,edge_index,posnew,pollinfor,batchinfo=igra.x,igra.edge_index,igra.pos.float(),igra.pollinfor,igra.batch\n",
    "        gx=torch.cat((igra.x[:,0:2],igra.x[:,-3:],posnew),dim=-1).float()\n",
    "        x1=self.c1(x)\n",
    "        cnng=cnntogra(posnew,batchinfo,x1)\n",
    "        # print(gx.shape,cnng.shape)\n",
    "        gout=self.g1(torch.cat((gx,cnng),dim=-1),edge_index)\n",
    "        return x1,gout\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FlexibleCNN(nn.Module):\n",
    "    def __init__(self, num_layers=1, in_channels=1, out_channels=1, mid_channels=16, activation_fn=nn.ReLU):\n",
    "        super(FlexibleCNN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.activation = activation_fn()\n",
    "        if num_layers > 1:\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, stride=1),\n",
    "                self.activation\n",
    "            ))\n",
    "        else:\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=1),\n",
    "                self.activation\n",
    "            ))\n",
    "        for _ in range(1, num_layers-1):\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Conv2d(mid_channels, mid_channels, kernel_size=3, padding=1, stride=1),\n",
    "                self.activation\n",
    "            ))\n",
    "        if num_layers > 1:\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, stride=1),\n",
    "                nn.Identity()\n",
    "            ))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class CNNadgnnIdent_extrCNN(nn.Module): ###https://doi.org/10.1016/j.mechmat.2021.104191\n",
    "    def __init__(self,chlist=[8,32,64,128,128,128,128,128,64,32,9]):\n",
    "        super().__init__()\n",
    "        self.c1=Modfiedunet4shrink()\n",
    "        self.cextra=FlexibleCNN(num_layers=4, mid_channels=64)\n",
    "        # self.g1=GraphSAGE(in_channels=int(8),hidden_channels=int(128), \n",
    "        #                         num_layers=4, out_channels=1)\n",
    "    def forward(self, igra):\n",
    "        x=igra.xdata128.float()\n",
    "        gx,edge_index,posnew,pollinfor,batchinfo=igra.x,igra.edge_index,igra.pos.float(),igra.pollinfor,igra.batch\n",
    "        gx=torch.cat((igra.x[:,0:2],igra.x[:,-3:],posnew),dim=-1).float()\n",
    "        x1=self.c1(x)\n",
    "        x1=self.cextra(x1)\n",
    "        cnng=cnntogra(posnew,batchinfo,x1)\n",
    "        # print(gx.shape,cnng.shape)\n",
    "        # gout=self.g1(torch.cat((gx,cnng),dim=-1),edge_index)\n",
    "        return x1,cnng\n",
    "    \n",
    "\n",
    "\n",
    "def getcnnloss(Xtrain,predicted,Ytrain,highvalue):\n",
    "    mask=Xtrain[:,0,:,:]==1\n",
    "    predictedT=torch.transpose(predicted,1,3)\n",
    "    predictedT=torch.transpose(predictedT,2,1)\n",
    "    YtrainT=torch.transpose(Ytrain,1,3)\n",
    "    YtrainT=torch.transpose(YtrainT,2,1)\n",
    "    midpre=predictedT[mask]\n",
    "    YtrainTmask=YtrainT[mask]\n",
    "    errors = torch.abs(midpre-YtrainTmask)\n",
    "    lossdif = torch.mean(errors)\n",
    "\n",
    "    #####get error for highstress area\n",
    "    highmask=YtrainTmask>=highvalue\n",
    "    YtrainThighmask=YtrainTmask[highmask]\n",
    "    midprehighmask=midpre[highmask]\n",
    "    losshighstress=torch.mean(torch.abs(YtrainThighmask-midprehighmask))\n",
    "\n",
    "\n",
    "    return losshighstress+lossdif, losshighstress\n",
    "\n",
    "import torch\n",
    "\n",
    "def getcnnloss(Xtrain, predicted, Ytrain,highvalue, percentile=80):\n",
    "    \"\"\"\n",
    "    计算损失函数，包括整体损失和基于百分位数确定的高值区域损失。\n",
    "\n",
    "    参数:\n",
    "    Xtrain -- 输入数据其中第一个通道用于生成掩码标记Ytrain中的非负值\n",
    "    predicted -- 预测值\n",
    "    Ytrain -- 实际值\n",
    "    percentile -- 用于确定高值区域的百分位数 (默认是80即高于80%的值)\n",
    "\n",
    "    返回:\n",
    "    total_loss -- 整体损失和高值区域损失的总和\n",
    "    high_stress_loss -- 高值区域的损失\n",
    "    \"\"\"\n",
    "    # 确保 Xtrain 第一个通道中值为1的位置, 这些是非负数的位置\n",
    "    non_negative_mask = Xtrain[:, 0, :, :] == 1\n",
    "    \n",
    "    # 应用掩码，调整掩码的维度以匹配Ytrain和predicted的维度\n",
    "    Ytrain_non_negative = Ytrain[:, 0, :, :][non_negative_mask]\n",
    "    predicted_non_negative = predicted[:, 0, :, :][non_negative_mask]\n",
    "    \n",
    "    # 计算整体平均绝对误差\n",
    "    overall_errors = torch.abs(predicted_non_negative - Ytrain_non_negative)\n",
    "    overall_mean_error = torch.mean(overall_errors)\n",
    "    \n",
    "    # 确定高值区域的阈值\n",
    "    k = int(len(Ytrain_non_negative) * (1 - percentile / 100))\n",
    "    threshold = Ytrain_non_negative.kthvalue(k).values if k > 0 else Ytrain_non_negative.min()\n",
    "    \n",
    "    # 高值掩码\n",
    "    high_value_mask = Ytrain_non_negative >= threshold\n",
    "    \n",
    "    # 高值区域的数据\n",
    "    Ytrain_high = Ytrain_non_negative[high_value_mask]\n",
    "    predicted_high = predicted_non_negative[high_value_mask]\n",
    "    \n",
    "    # 高值区域的平均绝对误差\n",
    "    high_stress_errors = torch.abs(predicted_high - Ytrain_high)\n",
    "    high_stress_mean_error = torch.mean(high_stress_errors)\n",
    "    \n",
    "    # 计算总损失\n",
    "    total_loss = overall_mean_error+high_stress_mean_error \n",
    "    \n",
    "    return overall_mean_error, high_stress_mean_error\n",
    "\n",
    "\n",
    "\n",
    "def getgnnhighloss_value(igra_svon, gx5final, igra_batch, threshold_value):\n",
    "    # igra_svon shape [node_number, 1] # the stress value of the nodes\n",
    "    # gx5final shape [node_number, 1] # the predicted stress value of the nodes\n",
    "    # igra_batch shape [node_number] # the batch of the nodes to each design\n",
    "\n",
    "    # Flatten to 1D array for subsequent operations\n",
    "    igra_svon = igra_svon.view(-1)\n",
    "    gx5final = gx5final.view(-1)\n",
    "\n",
    "    # Select nodes with stress value greater than the threshold\n",
    "    high_stress_mask = (igra_svon >= threshold_value)\n",
    "\n",
    "    # Extract the relevant stress values\n",
    "    real_high_stress = igra_svon[high_stress_mask]\n",
    "    pred_high_stress = gx5final[high_stress_mask]\n",
    "\n",
    "    # Ensure there are nodes exceeding the threshold\n",
    "    if real_high_stress.numel() > 0:\n",
    "        # Calculate MAPE, adding a small epsilon to avoid division by zero\n",
    "        epsilon = 1e-8\n",
    "        percentage_errors = torch.abs((real_high_stress - pred_high_stress) / (real_high_stress + epsilon))\n",
    "        avg_high_mape = torch.mean(percentage_errors) * 100  # Convert to percentage\n",
    "    else:\n",
    "        avg_high_mape = torch.tensor(0.0)\n",
    "\n",
    "    return avg_high_mape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getgnnhighloss(igra_svon, gx5final, igra_batch, percentile=80):\n",
    "\n",
    "    # igra_svon shape [node_number, 1] # the stress value of the nodes\n",
    "    # gx5final shape [node_number, 1] # the predicted stress value of the nodes\n",
    "    # igra_batch shape [node_number] # the batch of the nodes to each design\n",
    "\n",
    "    # 展平为一维数组，便于后续操作\n",
    "    igra_svon = igra_svon.view(-1)\n",
    "    gx5final = gx5final.view(-1)\n",
    "\n",
    "    # 按照 batch 分组计算每个设计的百分位数\n",
    "    unique_batches = torch.unique(igra_batch)\n",
    "    percentiles = torch.zeros_like(unique_batches, dtype=torch.float32)\n",
    "\n",
    "    # 计算每个设计的 80% 百分位数\n",
    "    for i, batch in enumerate(unique_batches):\n",
    "        mask = (igra_batch == batch)\n",
    "        percentiles[i] = torch.quantile(igra_svon[mask], percentile / 100.0)\n",
    "\n",
    "    # 将 percentile 映射回节点对应的批次\n",
    "    batch_percentiles = percentiles[igra_batch]\n",
    "\n",
    "    # 筛选出应力值大于百分位数阈值的节点\n",
    "    high_stress_mask = (igra_svon >= batch_percentiles)\n",
    "\n",
    "    # 计算筛选出的节点的 MAE\n",
    "    real_high_stress = igra_svon[high_stress_mask]\n",
    "    pred_high_stress = gx5final[high_stress_mask]\n",
    "\n",
    "    # 确保存在超过阈值的节点，计算 MAE\n",
    "    if real_high_stress.numel() > 0:\n",
    "        avg_high_mae = torch.mean(torch.abs(real_high_stress - pred_high_stress))\n",
    "    else:\n",
    "        avg_high_mae = torch.tensor(0.0)\n",
    "\n",
    "    return avg_high_mae\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7587294\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m=\u001b[39mmeshpoolresSAGEmodelUnet241012(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m      4\u001b[0m         hidden_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m,\n\u001b[0;32m      5\u001b[0m         out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      6\u001b[0m         depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m      7\u001b[0m         messpnum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters()))\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCNNadgnnIdent_GNNmeshpo\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule): \u001b[38;5;66;03m###https://doi.org/10.1016/j.mechmat.2021.104191\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,chlist\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m9\u001b[39m]):\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "from GraphUnet_define import meshpoolresSAGEmodelUnet241012\n",
    "\n",
    "model=meshpoolresSAGEmodelUnet241012(in_channels=8,\n",
    "        hidden_channels=11,\n",
    "        out_channels=1,\n",
    "        depth=4,\n",
    "        messpnum=4)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "class CNNadgnnIdent_GNNmeshpo(nn.Module): ###https://doi.org/10.1016/j.mechmat.2021.104191\n",
    "    def __init__(self,chlist=[8,32,64,128,128,128,128,128,64,32,9]):\n",
    "        super().__init__()\n",
    "        # self.c1=Modfiedunet4shrink(chin=1,k=4)\n",
    "        self.c1=Modfiedunet4shrink(chin=1)\n",
    "        # self.c1=Modfiedunet_CMAME(chin=1)\n",
    "        # self.c1=Modfiedunet3shrink_CMAME(chin=1,k=8)\n",
    "        self.g1=meshpoolresSAGEmodelUnet241012(in_channels=6,\n",
    "        hidden_channels=16,\n",
    "        out_channels=1,\n",
    "        depth=4,\n",
    "        messpnum=2)\n",
    "\n",
    "    def forward(self, igra):\n",
    "        x=igra.xdata128.float()\n",
    "        first_channel = x[:, 0:1, :, :]\n",
    "        x= first_channel\n",
    "\n",
    "        gx,edge_index,posnew,pollinfor,batchinfo=igra.x,igra.edge_index,igra.pos.float(),igra.pollinfor,igra.batch\n",
    "        gx=torch.cat((igra.x,posnew),dim=-1).float()\n",
    "        x1=self.c1(x)\n",
    "        cnng=cnntogra(posnew,batchinfo,x1)\n",
    "        # print(gx.shape,cnng.shape)\n",
    "        gout=self.g1(torch.cat((cnng,gx),dim=-1),edge_index,posnew,pollinfor,batchinfo)\n",
    " \n",
    "        return x1,gout\n",
    "    \n",
    "\n",
    "class CNNadgnnIdent_GNNmeshpo_7M(nn.Module): ###https://doi.org/10.1016/j.mechmat.2021.104191\n",
    "    def __init__(self,chlist=[8,32,64,128,128,128,128,128,64,32,9]):\n",
    "        super().__init__()\n",
    "        # self.c1=Modfiedunet4shrink(chin=1,k=4)\n",
    "        self.c1=Modfiedunet4shrink(chin=1)\n",
    "        # self.c1=Modfiedunet_CMAME(chin=1)\n",
    "        # self.c1=Modfiedunet3shrink_CMAME(chin=1,k=8)\n",
    "        self.g1=meshpoolresSAGEmodelUnet241012(in_channels=6,\n",
    "        hidden_channels=4,\n",
    "        out_channels=1,\n",
    "        depth=4,\n",
    "        messpnum=2)\n",
    "\n",
    "    def forward(self, igra):\n",
    "        x=igra.xdata128.float()\n",
    "        first_channel = x[:, 0:1, :, :]\n",
    "        x= first_channel\n",
    "\n",
    "        gx,edge_index,posnew,pollinfor,batchinfo=igra.x,igra.edge_index,igra.pos.float(),igra.pollinfor,igra.batch\n",
    "        gx=torch.cat((igra.x,posnew),dim=-1).float()\n",
    "        x1=self.c1(x)\n",
    "        cnng=cnntogra(posnew,batchinfo,x1)\n",
    "        # print(gx.shape,cnng.shape)\n",
    "        gout=self.g1(torch.cat((cnng,gx),dim=-1),edge_index,posnew,pollinfor,batchinfo)\n",
    " \n",
    "        return x1,gout\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class CNNadgnnIdent_GNNmeshpo_small(nn.Module): ###https://doi.org/10.1016/j.mechmat.2021.104191\n",
    "    def __init__(self,chlist=[8,32,64,128,128,128,128,128,64,32,9]):\n",
    "        super().__init__()\n",
    "        self.c1=Modfiedunet4shrink(chin=1,k=4)\n",
    "        # self.c1=Modfiedunet_CMAME(chin=1)\n",
    "        # self.c1=Modfiedunet3shrink_CMAME(chin=1,k=8)\n",
    "        self.g1=meshpoolresSAGEmodelUnet241012(in_channels=6,\n",
    "        hidden_channels=16,\n",
    "        out_channels=1,\n",
    "        depth=4,\n",
    "        messpnum=2)\n",
    "\n",
    "    def forward(self, igra):\n",
    "        x=igra.xdata128.float()\n",
    "        first_channel = x[:, 0:1, :, :]\n",
    "        x= first_channel\n",
    "\n",
    "        gx,edge_index,posnew,pollinfor,batchinfo=igra.x,igra.edge_index,igra.pos.float(),igra.pollinfor,igra.batch\n",
    "        gx=torch.cat((igra.x,posnew),dim=-1).float()\n",
    "        x1=self.c1(x)\n",
    "        cnng=cnntogra(posnew,batchinfo,x1)\n",
    "        # print(gx.shape,cnng.shape)\n",
    "        gout=self.g1(torch.cat((cnng,gx),dim=-1),edge_index,posnew,pollinfor,batchinfo)\n",
    " \n",
    "        return x1,gout\n",
    "    \n",
    "\n",
    "\n",
    "class CNNadgnnIdent_GNNmeshpo_GNNonly_small(nn.Module): ###https://doi.org/10.1016/j.mechmat.2021.104191\n",
    "    def __init__(self,chlist=[8,32,64,128,128,128,128,128,64,32,9]):\n",
    "        super().__init__()\n",
    "        # self.c1=Modfiedunet4shrink(chin=1,k=4)\n",
    "        # self.c1=Modfiedunet_CMAME(chin=1)\n",
    "        # self.c1=Modfiedunet3shrink_CMAME(chin=1,k=8)\n",
    "        self.g1=meshpoolresSAGEmodelUnet241012(in_channels=5,\n",
    "        hidden_channels=16,\n",
    "        out_channels=1,\n",
    "        depth=4,\n",
    "        messpnum=2)\n",
    "\n",
    "    def forward(self, igra):\n",
    "        x=igra.xdata128.float()\n",
    "        first_channel = x[:, 0:1, :, :]\n",
    "        x= first_channel\n",
    "\n",
    "        gx,edge_index,posnew,pollinfor,batchinfo=igra.x,igra.edge_index,igra.pos.float(),igra.pollinfor,igra.batch\n",
    "        gx=torch.cat((igra.x,posnew),dim=-1).float()\n",
    "        x1=x\n",
    "        # cnng=cnntogra(posnew,batchinfo,x1)\n",
    "        # print(gx.shape,cnng.shape)\n",
    "        gout=self.g1(gx,edge_index,posnew,pollinfor,batchinfo)\n",
    " \n",
    "        return x1,gout\n",
    "\n",
    "\n",
    "class CNNadgnnIdent_GNNmeshpo_GNNonly_checksize(nn.Module): ###https://doi.org/10.1016/j.mechmat.2021.104191\n",
    "    def __init__(self,hidden_channels,depth,messpnum,chlist=[8,32,64,128,128,128,128,128,64,32,9]):\n",
    "        super().__init__()\n",
    "        # self.c1=Modfiedunet4shrink(chin=1,k=4)\n",
    "        # self.c1=Modfiedunet_CMAME(chin=1)\n",
    "        # self.c1=Modfiedunet3shrink_CMAME(chin=1,k=8)\n",
    "        self.g1=meshpoolresSAGEmodelUnet241012(in_channels=5,\n",
    "        hidden_channels=hidden_channels,\n",
    "        out_channels=1,\n",
    "        depth=depth,\n",
    "        messpnum=messpnum)\n",
    "\n",
    "    def forward(self, igra):\n",
    "        x=igra.xdata128.float()\n",
    "        first_channel = x[:, 0:1, :, :]\n",
    "        x= first_channel\n",
    "\n",
    "        gx,edge_index,posnew,pollinfor,batchinfo=igra.x,igra.edge_index,igra.pos.float(),igra.pollinfor,igra.batch\n",
    "        gx=torch.cat((igra.x,posnew),dim=-1).float()\n",
    "        x1=x\n",
    "        # cnng=cnntogra(posnew,batchinfo,x1)\n",
    "        # print(gx.shape,cnng.shape)\n",
    "        gout=self.g1(gx,edge_index,posnew,pollinfor,batchinfo)\n",
    " \n",
    "        return x1,gout\n",
    "\n",
    "\n",
    "\n",
    "class CNNadgnnIdent_GNNmeshpo_GNNonly_7M(nn.Module): ###https://doi.org/10.1016/j.mechmat.2021.104191\n",
    "    def __init__(self,chlist=[8,32,64,128,128,128,128,128,64,32,9]):\n",
    "        super().__init__()\n",
    "        # self.c1=Modfiedunet4shrink(chin=1,k=4)\n",
    "        # self.c1=Modfiedunet_CMAME(chin=1)\n",
    "        # self.c1=Modfiedunet3shrink_CMAME(chin=1,k=8)\n",
    "        self.g1=meshpoolresSAGEmodelUnet241012(in_channels=5,\n",
    "        hidden_channels=11,\n",
    "        out_channels=1,\n",
    "        depth=4,\n",
    "        messpnum=4)\n",
    "\n",
    "    def forward(self, igra):\n",
    "        x=igra.xdata128.float()\n",
    "        first_channel = x[:, 0:1, :, :]\n",
    "        x= first_channel\n",
    "\n",
    "        gx,edge_index,posnew,pollinfor,batchinfo=igra.x,igra.edge_index,igra.pos.float(),igra.pollinfor,igra.batch\n",
    "        gx=torch.cat((igra.x,posnew),dim=-1).float()\n",
    "        x1=x\n",
    "        # cnng=cnntogra(posnew,batchinfo,x1)\n",
    "        # print(gx.shape,cnng.shape)\n",
    "        gout=self.g1(gx,edge_index,posnew,pollinfor,batchinfo)\n",
    " \n",
    "        return x1,gout\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in GraphSAGE model: 68225\n",
      "Number of parameters in MLP model: 67329\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "\n",
    "# Define GraphSAGE model\n",
    "class GraphSAGEModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphSAGEModel, self).__init__()\n",
    "        self.g1 = GraphSAGE(in_channels=8, hidden_channels=128, num_layers=4, out_channels=1)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        return self.g1(x, edge_index)\n",
    "\n",
    "# Define MLP model\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(8, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "# Instantiate the models\n",
    "graph_sage_model = GraphSAGEModel()\n",
    "mlp_model = MLPModel()\n",
    "\n",
    "# Calculate the number of parameters in each model\n",
    "graph_sage_params = sum(p.numel() for p in graph_sage_model.parameters())\n",
    "mlp_params = sum(p.numel() for p in mlp_model.parameters())\n",
    "\n",
    "print(f\"Number of parameters in GraphSAGE model: {graph_sage_params}\")\n",
    "print(f\"Number of parameters in MLP model: {mlp_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getgnnhighloss_mape(igra_svon, gx5final, igra_batch, percentile=80):\n",
    "\n",
    "    # igra_svon shape [node_number, 1] # the stress value of the nodes\n",
    "    # gx5final shape [node_number, 1] # the predicted stress value of the nodes\n",
    "    # igra_batch shape [node_number] # the batch of the nodes to each design\n",
    "\n",
    "    # 展平为一维数组，便于后续操作\n",
    "    igra_svon = igra_svon.view(-1)\n",
    "    gx5final = gx5final.view(-1)\n",
    "\n",
    "    # 按照 batch 分组计算每个设计的百分位数\n",
    "    unique_batches = torch.unique(igra_batch)\n",
    "    percentiles = torch.zeros_like(unique_batches, dtype=torch.float32)\n",
    "\n",
    "    # 计算每个设计的 80% 百分位数\n",
    "    for i, batch in enumerate(unique_batches):\n",
    "        mask = (igra_batch == batch)\n",
    "        percentiles[i] = torch.quantile(igra_svon[mask], percentile / 100.0)\n",
    "\n",
    "    # 将 percentile 映射回节点对应的批次\n",
    "    batch_percentiles = percentiles[igra_batch]\n",
    "\n",
    "    # 筛选出应力值大于百分位数阈值的节点\n",
    "    high_stress_mask = (igra_svon >= batch_percentiles)\n",
    "\n",
    "    # 计算筛选出的节点的 MAE\n",
    "    real_high_stress = igra_svon[high_stress_mask]\n",
    "    pred_high_stress = gx5final[high_stress_mask]\n",
    "\n",
    "    # 确保存在超过阈值的节点，计算 MAE\n",
    "    if real_high_stress.numel() > 0:\n",
    "        avg_high_mae = torch.mean(torch.abs(real_high_stress - pred_high_stress)/real_high_stress)\n",
    "    else:\n",
    "        avg_high_mae = torch.tensor(0.0)\n",
    "\n",
    "    return avg_high_mae\n",
    "\n",
    "\n",
    "def getcnnhighloss_mape(Xtrain, predicted, Ytrain,percentile=80):\n",
    "    \"\"\"\n",
    "    计算损失函数，包括整体损失和基于百分位数确定的高值区域损失。\n",
    "\n",
    "    参数:\n",
    "    Xtrain -- 输入数据其中第一个通道用于生成掩码标记Ytrain中的非负值\n",
    "    predicted -- 预测值\n",
    "    Ytrain -- 实际值\n",
    "    percentile -- 用于确定高值区域的百分位数 (默认是80即高于80%的值)\n",
    "\n",
    "    返回:\n",
    "    total_loss -- 整体损失和高值区域损失的总和\n",
    "    high_stress_loss -- 高值区域的损失\n",
    "    \"\"\"\n",
    "    # 确保 Xtrain 第一个通道中值为1的位置, 这些是非负数的位置\n",
    "    non_negative_mask = Ytrain[:, 0, :, :] != -10\n",
    "    \n",
    "    # 应用掩码，调整掩码的维度以匹配Ytrain和predicted的维度\n",
    "    Ytrain_non_negative = Ytrain[:, 0, :, :][non_negative_mask]\n",
    "    predicted_non_negative = predicted[:, 0, :, :][non_negative_mask]\n",
    "    \n",
    "    # 确定高值区域的阈值\n",
    "    k = int(len(Ytrain_non_negative) * (1 - percentile / 100))\n",
    "    threshold = Ytrain_non_negative.kthvalue(k).values if k > 0 else Ytrain_non_negative.min()\n",
    "    \n",
    "    # 高值掩码\n",
    "    high_value_mask = Ytrain_non_negative >= threshold\n",
    "    \n",
    "    # 高值区域的数据\n",
    "    Ytrain_high = Ytrain_non_negative[high_value_mask]\n",
    "    predicted_high = predicted_non_negative[high_value_mask]\n",
    "    \n",
    "    # 高值区域的平均绝对误差\n",
    "    high_stress_errors = torch.abs(predicted_high - Ytrain_high)/Ytrain_high\n",
    "    high_stress_mean_error = torch.mean(high_stress_errors)\n",
    "    \n",
    "  \n",
    "    \n",
    "    return high_stress_mean_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getcnnhighloss(Xtrain, predicted, Ytrain,percentile=80):\n",
    "    \"\"\"\n",
    "    计算损失函数，包括整体损失和基于百分位数确定的高值区域损失。\n",
    "\n",
    "    参数:\n",
    "    Xtrain -- 输入数据其中第一个通道用于生成掩码标记Ytrain中的非负值\n",
    "    predicted -- 预测值\n",
    "    Ytrain -- 实际值\n",
    "    percentile -- 用于确定高值区域的百分位数 (默认是80即高于80%的值)\n",
    "\n",
    "    返回:\n",
    "    total_loss -- 整体损失和高值区域损失的总和\n",
    "    high_stress_loss -- 高值区域的损失\n",
    "    \"\"\"\n",
    "    # 确保 Xtrain 第一个通道中值为1的位置, 这些是非负数的位置\n",
    "    non_negative_mask = Ytrain[:, 0, :, :] != -10\n",
    "    \n",
    "    # 应用掩码，调整掩码的维度以匹配Ytrain和predicted的维度\n",
    "    Ytrain_non_negative = Ytrain[:, 0, :, :][non_negative_mask]\n",
    "    predicted_non_negative = predicted[:, 0, :, :][non_negative_mask]\n",
    "    \n",
    "    # 确定高值区域的阈值\n",
    "    k = int(len(Ytrain_non_negative) * (1 - percentile / 100))\n",
    "    threshold = Ytrain_non_negative.kthvalue(k).values if k > 0 else Ytrain_non_negative.min()\n",
    "    \n",
    "    # 高值掩码\n",
    "    high_value_mask = Ytrain_non_negative >= threshold\n",
    "    \n",
    "    # 高值区域的数据\n",
    "    Ytrain_high = Ytrain_non_negative[high_value_mask]\n",
    "    predicted_high = predicted_non_negative[high_value_mask]\n",
    "    \n",
    "    # 高值区域的平均绝对误差\n",
    "    high_stress_errors = torch.abs(predicted_high - Ytrain_high)\n",
    "    high_stress_mean_error = torch.mean(high_stress_errors)\n",
    "    \n",
    "  \n",
    "    \n",
    "    return high_stress_mean_error\n",
    "\n",
    "\n",
    "\n",
    "class CNNadgnnIdent_modifiedunet(nn.Module): ###https://doi.org/10.1016/j.mechmat.2021.104191\n",
    "    def __init__(self,chlist=[8,32,64,128,128,128,128,128,64,32,9]):\n",
    "        super().__init__()\n",
    "        self.c1=Modfiedunet4shrink(chin=4)\n",
    "        # self.g1=GraphSAGE(in_channels=int(8),hidden_channels=int(128), \n",
    "        #                         num_layers=4, out_channels=1)\n",
    "\n",
    "    def forward(self, igra):\n",
    "        x=igra.xdata128.float()\n",
    "        # first_channel = x[:, 0:1, :, :]\n",
    "        # x= first_channel\n",
    "\n",
    "        # gx,edge_index,posnew,pollinfor,batchinfo=igra.x,igra.edge_index,igra.pos.float(),igra.pollinfor,igra.batch\n",
    "        # gx=torch.cat((igra.x[:,0:2],igra.x[:,-3:],posnew),dim=-1).float()\n",
    "        x1=self.c1(x)\n",
    "        # cnng=cnntogra(posnew,batchinfo,x1)\n",
    "        # print(gx.shape,cnng.shape)\n",
    "        # gout=self.g1(torch.cat((gx,cnng),dim=-1),edge_index)\n",
    "        gout = torch.zeros_like(igra.y)\n",
    "        return x1,gout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Meshgraphnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
